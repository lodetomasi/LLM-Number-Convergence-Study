{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe458d2-4067-4d5c-9e47-3364fcbf3256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T17:33:49.826935Z",
     "iopub.status.busy": "2025-07-19T17:33:49.826474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"font-family: monospace; padding: 10px; background-color: #f0f0f0; border-radius: 5px;\">\n",
       "            <h3>üî¨ Esperimento in corso...</h3>\n",
       "            <div style=\"margin: 10px 0;\">\n",
       "                <strong>Progresso:</strong> [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 25.3%\n",
       "            </div>\n",
       "            <div style=\"margin: 5px 0;\">\n",
       "                <strong>Test completati:</strong> 38 / 150\n",
       "            </div>\n",
       "            <div style=\"margin: 5px 0; color: #666;\">\n",
       "                Testing Gemini 2.0 | Range: 1-50 | Prompt: random\n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "LLM Number Selection Convergence Experiment - Jupyter Notebook Version\n",
    "====================================================================\n",
    "This experiment tests multiple Large Language Models to analyze\n",
    "convergence patterns in pseudo-random number selection.\n",
    "\n",
    "Research Question: Do different LLMs exhibit similar biases when asked\n",
    "to select \"random\" numbers within given ranges?\n",
    "\"\"\"\n",
    "\n",
    "# %% [markdown]\n",
    "# # LLM Number Selection Convergence Experiment\n",
    "# \n",
    "# ## Obiettivo della Ricerca\n",
    "# Analizzare se diversi Large Language Models mostrano pattern di convergenza simili quando viene chiesto loro di selezionare numeri \"casuali\" in un dato intervallo.\n",
    "# \n",
    "# ## Ipotesi\n",
    "# I modelli LLM, addestrati su dati simili, potrebbero mostrare bias cognitivi convergenti nella selezione di numeri pseudo-casuali.\n",
    "\n",
    "# %% Cell 1: Import e Configurazione\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from openai import OpenAI\n",
    "from collections import Counter, defaultdict\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML, clear_output, Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurazione dello stile per grafici pi√π belli\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Librerie importate con successo!\")\n",
    "\n",
    "# %% Cell 2: Configurazione API e Modelli\n",
    "class ExperimentConfig:\n",
    "    \"\"\"Classe per gestire la configurazione dell'esperimento\"\"\"\n",
    "    \n",
    "    # OpenRouter Configuration\n",
    "    OPENROUTER_API_KEY = \"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\"\n",
    "    BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "    \n",
    "    # Modelli da testare\n",
    "    MODELS = [\n",
    "        \"openai/gpt-4o\",\n",
    "        \"anthropic/claude-3.5-sonnet\", \n",
    "        \"google/gemini-2.0-flash-exp:free\",\n",
    "        \"meta-llama/llama-3.1-70b-instruct\",\n",
    "        \"mistralai/mistral-large\"\n",
    "    ]\n",
    "    \n",
    "    # Configurazione esperimento\n",
    "    TEMPERATURE = 0.7  # Temperatura per simulare casualit√†\n",
    "    MAX_RETRIES = 3\n",
    "    DELAY_BETWEEN_CALLS = 0.5\n",
    "    \n",
    "    # Range di test\n",
    "    TEST_RANGES = [\n",
    "        (1, 10),    # Range piccolo\n",
    "        (1, 50),    # Range medio (quello originale)\n",
    "        (1, 100),   # Range grande\n",
    "        (0, 9),     # Single digit\n",
    "        (1, 1000)   # Range molto grande\n",
    "    ]\n",
    "    \n",
    "    # Prompt templates\n",
    "    PROMPT_TEMPLATES = {\n",
    "        \"simple\": \"Pick a number between {min} and {max}\",\n",
    "        \"random\": \"Pick a random number between {min} and {max}\",\n",
    "        \"think\": \"Think of a number between {min} and {max}\",\n",
    "        \"choose\": \"Please choose any number between {min} and {max}\",\n",
    "        \"select\": \"Select a number between {min} and {max}\",\n",
    "        \"generate\": \"Generate a number between {min} and {max}\"\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def get_display_name(cls, model: str) -> str:\n",
    "        \"\"\"Ottiene un nome pi√π leggibile per il modello\"\"\"\n",
    "        model_names = {\n",
    "            \"openai/gpt-4o\": \"GPT-4\",\n",
    "            \"anthropic/claude-3.5-sonnet\": \"Claude 3.5\",\n",
    "            \"google/gemini-2.0-flash-exp:free\": \"Gemini 2.0\",\n",
    "            \"meta-llama/llama-3.1-70b-instruct\": \"Llama 3.1\",\n",
    "            \"mistralai/mistral-large\": \"Mistral Large\"\n",
    "        }\n",
    "        return model_names.get(model, model.split('/')[-1])\n",
    "\n",
    "print(f\"‚úÖ Configurazione completata!\")\n",
    "print(f\"üìä Modelli da testare: {len(ExperimentConfig.MODELS)}\")\n",
    "print(f\"üìè Range di test: {len(ExperimentConfig.TEST_RANGES)}\")\n",
    "print(f\"üí¨ Varianti di prompt: {len(ExperimentConfig.PROMPT_TEMPLATES)}\")\n",
    "\n",
    "# %% Cell 3: Classe Principale per l'Esperimento\n",
    "class NumberConvergenceExperiment:\n",
    "    \"\"\"Classe principale per gestire l'esperimento di convergenza numerica\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = OpenAI(\n",
    "            api_key=ExperimentConfig.OPENROUTER_API_KEY,\n",
    "            base_url=ExperimentConfig.BASE_URL\n",
    "        )\n",
    "        self.results = []\n",
    "        self.current_experiment = {\n",
    "            'start_time': datetime.now(),\n",
    "            'completed_tests': 0,\n",
    "            'total_tests': 0\n",
    "        }\n",
    "        \n",
    "    def call_model(self, model: str, prompt: str, temperature: float = None) -> Optional[str]:\n",
    "        \"\"\"Chiama un modello tramite OpenRouter API\"\"\"\n",
    "        if temperature is None:\n",
    "            temperature = ExperimentConfig.TEMPERATURE\n",
    "            \n",
    "        for attempt in range(ExperimentConfig.MAX_RETRIES):\n",
    "            try:\n",
    "                response = self.client.chat.completions.create(\n",
    "                    extra_headers={\n",
    "                        \"HTTP-Referer\": \"https://github.com/llm-convergence-experiment\",\n",
    "                        \"X-Title\": \"Number Selection Convergence Study\",\n",
    "                    },\n",
    "                    model=model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=temperature,\n",
    "                    max_tokens=50\n",
    "                )\n",
    "                return response.choices[0].message.content.strip()\n",
    "                \n",
    "            except Exception as e:\n",
    "                if attempt < ExperimentConfig.MAX_RETRIES - 1:\n",
    "                    time.sleep(2 ** attempt)\n",
    "                else:\n",
    "                    return None\n",
    "    \n",
    "    def extract_number(self, response: str, min_val: int, max_val: int) -> Optional[int]:\n",
    "        \"\"\"Estrae un numero dalla risposta del modello\"\"\"\n",
    "        if response is None:\n",
    "            return None\n",
    "            \n",
    "        import re\n",
    "        numbers = re.findall(r'\\b\\d+\\b', response)\n",
    "        \n",
    "        for num_str in numbers:\n",
    "            try:\n",
    "                num = int(num_str)\n",
    "                if min_val <= num <= max_val:\n",
    "                    return num\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        return None\n",
    "    \n",
    "    def run_single_test(self, model: str, prompt_template: str, \n",
    "                       min_val: int, max_val: int, \n",
    "                       num_iterations: int = 10) -> List[int]:\n",
    "        \"\"\"Esegue un test singolo su un modello\"\"\"\n",
    "        numbers = []\n",
    "        model_name = ExperimentConfig.get_display_name(model)\n",
    "        \n",
    "        for i in range(num_iterations):\n",
    "            prompt = prompt_template.format(min=min_val, max=max_val)\n",
    "            response = self.call_model(model, prompt)\n",
    "            number = self.extract_number(response, min_val, max_val)\n",
    "            \n",
    "            if number is not None:\n",
    "                numbers.append(number)\n",
    "                \n",
    "            time.sleep(ExperimentConfig.DELAY_BETWEEN_CALLS)\n",
    "            \n",
    "        return numbers\n",
    "    \n",
    "    def display_progress(self, current: int, total: int, message: str = \"\"):\n",
    "        \"\"\"Mostra una barra di progresso interattiva\"\"\"\n",
    "        progress = current / total\n",
    "        bar_length = 50\n",
    "        filled_length = int(bar_length * progress)\n",
    "        bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display(HTML(f\"\"\"\n",
    "        <div style=\"font-family: monospace; padding: 10px; background-color: #f0f0f0; border-radius: 5px;\">\n",
    "            <h3>üî¨ Esperimento in corso...</h3>\n",
    "            <div style=\"margin: 10px 0;\">\n",
    "                <strong>Progresso:</strong> [{bar}] {progress*100:.1f}%\n",
    "            </div>\n",
    "            <div style=\"margin: 5px 0;\">\n",
    "                <strong>Test completati:</strong> {current} / {total}\n",
    "            </div>\n",
    "            <div style=\"margin: 5px 0; color: #666;\">\n",
    "                {message}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "\n",
    "# Inizializza l'esperimento\n",
    "experiment = NumberConvergenceExperiment()\n",
    "print(\"‚úÖ Esperimento inizializzato!\")\n",
    "\n",
    "# %% Cell 4: Funzioni di Analisi e Visualizzazione\n",
    "class AnalysisTools:\n",
    "    \"\"\"Strumenti per l'analisi dei risultati\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_entropy(numbers: List[int], min_val: int, max_val: int) -> float:\n",
    "        \"\"\"Calcola l'entropia di Shannon per misurare la casualit√†\"\"\"\n",
    "        if not numbers:\n",
    "            return 0\n",
    "        \n",
    "        # Conta le occorrenze\n",
    "        counts = Counter(numbers)\n",
    "        total = len(numbers)\n",
    "        \n",
    "        # Calcola l'entropia\n",
    "        entropy = 0\n",
    "        for count in counts.values():\n",
    "            if count > 0:\n",
    "                p = count / total\n",
    "                entropy -= p * np.log2(p)\n",
    "                \n",
    "        # Normalizza rispetto all'entropia massima\n",
    "        max_entropy = np.log2(max_val - min_val + 1)\n",
    "        return entropy / max_entropy if max_entropy > 0 else 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def find_convergence_points(all_results: Dict[str, List[int]]) -> Dict[int, float]:\n",
    "        \"\"\"Trova i punti di convergenza tra i modelli\"\"\"\n",
    "        all_numbers = []\n",
    "        for numbers in all_results.values():\n",
    "            all_numbers.extend(numbers)\n",
    "            \n",
    "        counter = Counter(all_numbers)\n",
    "        total_selections = sum(counter.values())\n",
    "        \n",
    "        convergence_points = {}\n",
    "        for number, count in counter.items():\n",
    "            # Calcola quanto spesso questo numero √® stato scelto\n",
    "            frequency = count / total_selections\n",
    "            # Considera convergenza se la frequenza √® significativamente alta\n",
    "            expected_frequency = 1 / (max(all_numbers) - min(all_numbers) + 1)\n",
    "            if frequency > expected_frequency * 2:  # Soglia: 2x la frequenza attesa\n",
    "                convergence_points[number] = frequency\n",
    "                \n",
    "        return convergence_points\n",
    "    \n",
    "    @staticmethod\n",
    "    def chi_square_test(results_dict: Dict[str, List[int]], min_val: int, max_val: int) -> float:\n",
    "        \"\"\"Test chi-quadro per verificare se le distribuzioni sono casuali\"\"\"\n",
    "        all_numbers = []\n",
    "        for numbers in results_dict.values():\n",
    "            all_numbers.extend(numbers)\n",
    "            \n",
    "        if not all_numbers:\n",
    "            return 1.0\n",
    "            \n",
    "        # Frequenze osservate\n",
    "        observed = Counter(all_numbers)\n",
    "        n_total = len(all_numbers)\n",
    "        n_values = max_val - min_val + 1\n",
    "        \n",
    "        # Frequenza attesa (distribuzione uniforme)\n",
    "        expected = n_total / n_values\n",
    "        \n",
    "        # Calcola chi-quadro\n",
    "        chi_square = 0\n",
    "        for i in range(min_val, max_val + 1):\n",
    "            observed_freq = observed.get(i, 0)\n",
    "            chi_square += (observed_freq - expected) ** 2 / expected\n",
    "            \n",
    "        # Calcola p-value\n",
    "        df = n_values - 1\n",
    "        p_value = 1 - stats.chi2.cdf(chi_square, df)\n",
    "        \n",
    "        return p_value\n",
    "\n",
    "print(\"‚úÖ Strumenti di analisi pronti!\")\n",
    "\n",
    "# %% Cell 5: Esecuzione Esperimento Base (Range 1-50)\n",
    "# Test iniziale con il range originale (1-50)\n",
    "display(Markdown(\"## üß™ Test 1: Range Originale (1-50)\"))\n",
    "display(Markdown(\"Riproduzione dell'esperimento originale dove tutti i modelli hanno scelto 27\"))\n",
    "\n",
    "results_1_50 = {}\n",
    "prompt = ExperimentConfig.PROMPT_TEMPLATES[\"simple\"]\n",
    "min_val, max_val = 1, 50\n",
    "\n",
    "for i, model in enumerate(ExperimentConfig.MODELS):\n",
    "    model_name = ExperimentConfig.get_display_name(model)\n",
    "    experiment.display_progress(i, len(ExperimentConfig.MODELS), \n",
    "                              f\"Testing {model_name} su range {min_val}-{max_val}\")\n",
    "    \n",
    "    numbers = experiment.run_single_test(model, prompt, min_val, max_val, num_iterations=20)\n",
    "    results_1_50[model_name] = numbers\n",
    "    \n",
    "    # Salva risultati\n",
    "    for num in numbers:\n",
    "        experiment.results.append({\n",
    "            'model': model_name,\n",
    "            'range': f\"{min_val}-{max_val}\",\n",
    "            'prompt_type': 'simple',\n",
    "            'number': num,\n",
    "            'timestamp': datetime.now()\n",
    "        })\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Visualizza i risultati\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Grafico 1: Distribuzione per modello\n",
    "for model_name, numbers in results_1_50.items():\n",
    "    if numbers:\n",
    "        ax1.hist(numbers, bins=20, alpha=0.5, label=model_name, density=True)\n",
    "\n",
    "ax1.set_xlabel('Numero Selezionato')\n",
    "ax1.set_ylabel('Densit√†')\n",
    "ax1.set_title('Distribuzione delle Selezioni per Modello (Range 1-50)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Grafico 2: Heatmap delle selezioni\n",
    "selection_matrix = np.zeros((len(results_1_50), 50))\n",
    "for i, (model_name, numbers) in enumerate(results_1_50.items()):\n",
    "    for num in numbers:\n",
    "        selection_matrix[i, num-1] += 1\n",
    "\n",
    "sns.heatmap(selection_matrix[:, 15:35], # Focus su range 16-35\n",
    "            xticklabels=range(16, 36),\n",
    "            yticklabels=list(results_1_50.keys()),\n",
    "            cmap='YlOrRd',\n",
    "            ax=ax2,\n",
    "            cbar_kws={'label': 'Frequenza'})\n",
    "ax2.set_title('Heatmap Selezioni (Focus: 16-35)')\n",
    "ax2.set_xlabel('Numero')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analisi statistica\n",
    "print(\"\\nüìä Analisi Statistica Range 1-50:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "convergence_points = AnalysisTools.find_convergence_points(results_1_50)\n",
    "if convergence_points:\n",
    "    print(f\"\\nüéØ Punti di Convergenza Identificati:\")\n",
    "    for num, freq in sorted(convergence_points.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   Numero {num}: {freq:.2%} delle selezioni\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Nessun punto di convergenza significativo trovato\")\n",
    "\n",
    "# Mostra i numeri pi√π frequenti per modello\n",
    "print(\"\\nüî¢ Numeri pi√π frequenti per modello:\")\n",
    "for model_name, numbers in results_1_50.items():\n",
    "    if numbers:\n",
    "        most_common = Counter(numbers).most_common(3)\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        for num, count in most_common:\n",
    "            print(f\"   {num}: {count} volte ({count/len(numbers)*100:.1f}%)\")\n",
    "\n",
    "# %% Cell 6: Test Multi-Range Completo\n",
    "display(Markdown(\"## üß™ Test 2: Analisi Multi-Range\"))\n",
    "display(Markdown(\"Test su diversi range per identificare pattern di convergenza\"))\n",
    "\n",
    "all_results = defaultdict(lambda: defaultdict(list))\n",
    "total_tests = len(ExperimentConfig.MODELS) * len(ExperimentConfig.TEST_RANGES) * len(ExperimentConfig.PROMPT_TEMPLATES)\n",
    "current_test = 0\n",
    "\n",
    "for range_tuple in ExperimentConfig.TEST_RANGES:\n",
    "    min_val, max_val = range_tuple\n",
    "    range_key = f\"{min_val}-{max_val}\"\n",
    "    \n",
    "    for prompt_name, prompt_template in ExperimentConfig.PROMPT_TEMPLATES.items():\n",
    "        for model in ExperimentConfig.MODELS:\n",
    "            current_test += 1\n",
    "            model_name = ExperimentConfig.get_display_name(model)\n",
    "            \n",
    "            experiment.display_progress(current_test, total_tests,\n",
    "                f\"Testing {model_name} | Range: {range_key} | Prompt: {prompt_name}\")\n",
    "            \n",
    "            numbers = experiment.run_single_test(model, prompt_template, min_val, max_val, num_iterations=10)\n",
    "            all_results[range_key][model_name].extend(numbers)\n",
    "            \n",
    "            # Salva risultati dettagliati\n",
    "            for num in numbers:\n",
    "                experiment.results.append({\n",
    "                    'model': model_name,\n",
    "                    'range': range_key,\n",
    "                    'prompt_type': prompt_name,\n",
    "                    'number': num,\n",
    "                    'timestamp': datetime.now()\n",
    "                })\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "# %% Cell 7: Visualizzazione Risultati Multi-Range\n",
    "display(Markdown(\"## üìä Risultati Analisi Multi-Range\"))\n",
    "\n",
    "# Crea DataFrame per analisi pi√π facile\n",
    "df_results = pd.DataFrame(experiment.results)\n",
    "\n",
    "# Figura 1: Convergenza per Range\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (range_key, range_data) in enumerate(all_results.items()):\n",
    "    if idx < len(axes):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Calcola la distribuzione aggregata\n",
    "        all_numbers = []\n",
    "        for model_numbers in range_data.values():\n",
    "            all_numbers.extend(model_numbers)\n",
    "        \n",
    "        if all_numbers:\n",
    "            # Trova i numeri pi√π comuni\n",
    "            counter = Counter(all_numbers)\n",
    "            numbers, counts = zip(*counter.most_common(10))\n",
    "            \n",
    "            # Crea bar plot\n",
    "            bars = ax.bar(numbers, counts, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "            \n",
    "            # Evidenzia il pi√π comune\n",
    "            max_idx = counts.index(max(counts))\n",
    "            bars[max_idx].set_color('red')\n",
    "            bars[max_idx].set_alpha(1.0)\n",
    "            \n",
    "            ax.set_title(f'Range {range_key}')\n",
    "            ax.set_xlabel('Numero')\n",
    "            ax.set_ylabel('Frequenza')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Rimuovi assi vuoti\n",
    "for idx in range(len(all_results), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.suptitle('Top 10 Numeri pi√π Selezionati per Range', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% Cell 8: Analisi della Convergenza Inter-Modello\n",
    "display(Markdown(\"## üîÑ Analisi Convergenza Inter-Modello\"))\n",
    "\n",
    "# Calcola la similarit√† tra modelli per ogni range\n",
    "similarity_matrices = {}\n",
    "\n",
    "for range_key, range_data in all_results.items():\n",
    "    models = list(range_data.keys())\n",
    "    n_models = len(models)\n",
    "    similarity_matrix = np.zeros((n_models, n_models))\n",
    "    \n",
    "    for i, model1 in enumerate(models):\n",
    "        for j, model2 in enumerate(models):\n",
    "            if i != j and range_data[model1] and range_data[model2]:\n",
    "                # Calcola l'overlap delle distribuzioni\n",
    "                set1 = set(range_data[model1])\n",
    "                set2 = set(range_data[model2])\n",
    "                \n",
    "                # Jaccard similarity\n",
    "                intersection = len(set1.intersection(set2))\n",
    "                union = len(set1.union(set2))\n",
    "                similarity = intersection / union if union > 0 else 0\n",
    "                \n",
    "                similarity_matrix[i, j] = similarity\n",
    "    \n",
    "    similarity_matrices[range_key] = similarity_matrix\n",
    "\n",
    "# Visualizza matrici di similarit√†\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (range_key, sim_matrix) in enumerate(similarity_matrices.items()):\n",
    "    if idx < len(axes) and sim_matrix.shape[0] > 0:\n",
    "        ax = axes[idx]\n",
    "        models = list(all_results[range_key].keys())\n",
    "        \n",
    "        sns.heatmap(sim_matrix, \n",
    "                    xticklabels=models,\n",
    "                    yticklabels=models,\n",
    "                    annot=True,\n",
    "                    fmt='.2f',\n",
    "                    cmap='RdYlBu_r',\n",
    "                    vmin=0, vmax=1,\n",
    "                    ax=ax,\n",
    "                    cbar_kws={'label': 'Similarit√†'})\n",
    "        ax.set_title(f'Similarit√† Inter-Modello - Range {range_key}')\n",
    "\n",
    "# Rimuovi assi vuoti\n",
    "for idx in range(len(similarity_matrices), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% Cell 9: Analisi Statistica Avanzata\n",
    "display(Markdown(\"## üìà Analisi Statistica Avanzata\"))\n",
    "\n",
    "# Test di casualit√† per ogni combinazione\n",
    "randomness_results = []\n",
    "\n",
    "for range_key, range_data in all_results.items():\n",
    "    min_val, max_val = map(int, range_key.split('-'))\n",
    "    \n",
    "    # Test chi-quadro\n",
    "    p_value = AnalysisTools.chi_square_test(range_data, min_val, max_val)\n",
    "    \n",
    "    # Calcola entropia media\n",
    "    entropies = []\n",
    "    for model_name, numbers in range_data.items():\n",
    "        if numbers:\n",
    "            entropy = AnalysisTools.calculate_entropy(numbers, min_val, max_val)\n",
    "            entropies.append(entropy)\n",
    "    \n",
    "    avg_entropy = np.mean(entropies) if entropies else 0\n",
    "    \n",
    "    randomness_results.append({\n",
    "        'Range': range_key,\n",
    "        'P-value (Chi¬≤)': f\"{p_value:.4f}\",\n",
    "        'Entropia Media': f\"{avg_entropy:.3f}\",\n",
    "        'Casualit√†': '‚úÖ Casuale' if p_value > 0.05 else '‚ùå Non casuale'\n",
    "    })\n",
    "\n",
    "# Mostra tabella risultati\n",
    "df_randomness = pd.DataFrame(randomness_results)\n",
    "display(HTML(df_randomness.to_html(index=False)))\n",
    "\n",
    "# %% Cell 10: Pattern Psicologici e Bias Cognitivi\n",
    "display(Markdown(\"## üß† Analisi dei Bias Cognitivi\"))\n",
    "\n",
    "# Analizza preferenze per tipi di numeri\n",
    "def analyze_number_properties(numbers: List[int]) -> Dict[str, float]:\n",
    "    \"\"\"Analizza le propriet√† dei numeri selezionati\"\"\"\n",
    "    if not numbers:\n",
    "        return {}\n",
    "    \n",
    "    total = len(numbers)\n",
    "    properties = {\n",
    "        'primi': sum(1 for n in numbers if is_prime(n)) / total,\n",
    "        'pari': sum(1 for n in numbers if n % 2 == 0) / total,\n",
    "        'multipli_5': sum(1 for n in numbers if n % 5 == 0) / total,\n",
    "        'potenze_2': sum(1 for n in numbers if n & (n-1) == 0 and n != 0) / total,\n",
    "        'cifra_singola': sum(1 for n in numbers if n < 10) / total,\n",
    "        'contiene_7': sum(1 for n in numbers if '7' in str(n)) / total\n",
    "    }\n",
    "    return properties\n",
    "\n",
    "def is_prime(n: int) -> bool:\n",
    "    \"\"\"Controlla se un numero √® primo\"\"\"\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Analizza bias per modello\n",
    "bias_analysis = defaultdict(dict)\n",
    "\n",
    "for model in ExperimentConfig.MODELS:\n",
    "    model_name = ExperimentConfig.get_display_name(model)\n",
    "    all_numbers = []\n",
    "    \n",
    "    # Raccogli tutti i numeri per questo modello\n",
    "    for range_data in all_results.values():\n",
    "        if model_name in range_data:\n",
    "            all_numbers.extend(range_data[model_name])\n",
    "    \n",
    "    if all_numbers:\n",
    "        bias_analysis[model_name] = analyze_number_properties(all_numbers)\n",
    "\n",
    "# Visualizza bias\n",
    "if bias_analysis:\n",
    "    df_bias = pd.DataFrame(bias_analysis).T\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    df_bias.plot(kind='bar', ax=ax)\n",
    "    ax.set_title('Bias Cognitivi nella Selezione dei Numeri per Modello')\n",
    "    ax.set_xlabel('Modello')\n",
    "    ax.set_ylabel('Proporzione')\n",
    "    ax.legend(title='Propriet√†', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# %% Cell 11: Report Finale e Conclusioni\n",
    "display(Markdown(\"## üìù Report Finale\"))\n",
    "\n",
    "# Genera statistiche riassuntive\n",
    "total_selections = len(experiment.results)\n",
    "models_tested = len(ExperimentConfig.MODELS)\n",
    "ranges_tested = len(ExperimentConfig.TEST_RANGES)\n",
    "prompts_tested = len(ExperimentConfig.PROMPT_TEMPLATES)\n",
    "\n",
    "# Trova il numero pi√π selezionato in assoluto\n",
    "all_numbers_global = [r['number'] for r in experiment.results]\n",
    "most_common_global = Counter(all_numbers_global).most_common(5)\n",
    "\n",
    "# Calcola tempo totale esperimento\n",
    "end_time = datetime.now()\n",
    "duration = end_time - experiment.current_experiment['start_time']\n",
    "\n",
    "# Crea report\n",
    "report_html = f\"\"\"\n",
    "<div style=\"background-color: #f0f0f0; padding: 20px; border-radius: 10px; font-family: Arial, sans-serif;\">\n",
    "    <h2 style=\"color: #2c3e50;\">üìä Report Esperimento Convergenza LLM</h2>\n",
    "    \n",
    "    <div style=\"background-color: white; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
    "        <h3>üîç Parametri Esperimento</h3>\n",
    "        <ul>\n",
    "            <li><strong>Modelli testati:</strong> {models_tested}</li>\n",
    "            <li><strong>Range numerici:</strong> {ranges_tested}</li>\n",
    "            <li><strong>Varianti prompt:</strong> {prompts_tested}</li>\n",
    "            <li><strong>Selezioni totali:</strong> {total_selections}</li>\n",
    "            <li><strong>Durata:</strong> {duration.total_seconds():.1f} secondi</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    \n",
    "    <div style=\"background-color: white; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
    "        <h3>üéØ Risultati Chiave</h3>\n",
    "        <h4>Top 5 Numeri pi√π Selezionati (Globale):</h4>\n",
    "        <ol>\n",
    "\"\"\"\n",
    "\n",
    "for num, count in most_common_global:\n",
    "    percentage = (count / total_selections) * 100\n",
    "    report_html += f\"<li><strong>{num}</strong>: {count} volte ({percentage:.1f}%)</li>\"\n",
    "\n",
    "report_html += \"\"\"\n",
    "        </ol>\n",
    "    </div>\n",
    "    \n",
    "    <div style=\"background-color: white; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
    "        <h3>üí° Conclusioni Principali</h3>\n",
    "        <ul>\n",
    "            <li>I modelli mostrano pattern di convergenza significativi in determinati range</li>\n",
    "            <li>Esistono \"numeri attrattori\" che vengono selezionati con frequenza superiore alla casualit√†</li>\n",
    "            <li>I bias cognitivi umani sembrano riflettersi nelle selezioni dei modelli</li>\n",
    "            <li>La formulazione del prompt influenza marginalmente la distribuzione delle selezioni</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(report_html))\n",
    "\n",
    "# %% Cell 12: Salvataggio Dati per Paper\n",
    "# Salva tutti i risultati per l'analisi nel paper\n",
    "output_data = {\n",
    "    \"metadata\": {\n",
    "        \"experiment_date\": datetime.now().isoformat(),\n",
    "        \"models_tested\": ExperimentConfig.MODELS,\n",
    "        \"ranges_tested\": ExperimentConfig.TEST_RANGES,\n",
    "        \"prompt_types\": list(ExperimentConfig.PROMPT_TEMPLATES.keys()),\n",
    "        \"total_selections\": total_selections,\n",
    "        \"duration_seconds\": duration.total_seconds()\n",
    "    },\n",
    "    \"raw_results\": experiment.results,\n",
    "    \"convergence_analysis\": {\n",
    "        range_key: {\n",
    "            \"convergence_points\": AnalysisTools.find_convergence_points(range_data),\n",
    "            \"model_selections\": {\n",
    "                model: Counter(numbers).most_common()\n",
    "                for model, numbers in range_data.items()\n",
    "            }\n",
    "        }\n",
    "        for range_key, range_data in all_results.items()\n",
    "    },\n",
    "    \"statistical_tests\": randomness_results,\n",
    "    \"bias_analysis\": dict(bias_analysis)\n",
    "}\n",
    "\n",
    "# Salva in JSON\n",
    "with open('llm_number_convergence_results.json', 'w') as f:\n",
    "    json.dump(output_data, f, indent=2, default=str)\n",
    "\n",
    "# Salva DataFrame in CSV per analisi facile\n",
    "df_results.to_csv('llm_number_selections.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Dati salvati con successo!\")\n",
    "print(\"üìÅ Files generati:\")\n",
    "print(\"   - llm_number_convergence_results.json\")\n",
    "print(\"   - llm_number_selections.csv\")\n",
    "\n",
    "# %% Cell 13: Visualizzazione Interattiva Finale\n",
    "display(Markdown(\"## üé® Visualizzazione Finale Interattiva\"))\n",
    "\n",
    "# Crea una visualizzazione riassuntiva elegante\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Distribuzione globale\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "all_nums = [r['number'] for r in experiment.results]\n",
    "ax1.hist(all_nums, bins=50, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "ax1.set_title('Distribuzione Globale delle Selezioni', fontsize=14)\n",
    "ax1.set_xlabel('Numero')\n",
    "ax1.set_ylabel('Frequenza')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Confronto modelli\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "model_counts = df_results.groupby('model')['number'].count()\n",
    "model_counts.plot(kind='bar', ax=ax2, color='lightcoral')\n",
    "ax2.set_title('Selezioni per Modello', fontsize=12)\n",
    "ax2.set_xlabel('')\n",
    "ax2.set_ylabel('Numero Selezioni')\n",
    "plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# 3. Heatmap convergenza range 1-50\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "range_1_50_data = all_results.get('1-50', {})\n",
    "if range_1_50_data:\n",
    "    convergence_matrix = np.zeros((len(range_1_50_data), 50))\n",
    "    for i, (model, numbers) in enumerate(range_1_50_data.items()):\n",
    "        for num in numbers:\n",
    "            convergence_matrix[i, num-1] += 1\n",
    "    \n",
    "    # Focus sui numeri 15-35\n",
    "    im = ax3.imshow(convergence_matrix[:, 14:35], aspect='auto', cmap='YlOrRd')\n",
    "    ax3.set_xticks(range(21))\n",
    "    ax3.set_xticklabels(range(15, 36))\n",
    "    ax3.set_yticks(range(len(range_1_50_data)))\n",
    "    ax3.set_yticklabels(list(range_1_50_data.keys()))\n",
    "    ax3.set_xlabel('Numero')\n",
    "    ax3.set_title('Heatmap Convergenza - Range 1-50 (Focus: 15-35)', fontsize=14)\n",
    "    plt.colorbar(im, ax=ax3, label='Frequenza')\n",
    "\n",
    "# 4. Entropia per range\n",
    "ax4 = fig.add_subplot(gs[2, 0])\n",
    "entropy_data = []\n",
    "for range_key, range_data in all_results.items():\n",
    "    min_val, max_val = map(int, range_key.split('-'))\n",
    "    for model, numbers in range_data.items():\n",
    "        if numbers:\n",
    "            entropy = AnalysisTools.calculate_entropy(numbers, min_val, max_val)\n",
    "            entropy_data.append({'Range': range_key, 'Entropy': entropy})\n",
    "\n",
    "if entropy_data:\n",
    "    df_entropy = pd.DataFrame(entropy_data)\n",
    "    df_entropy.boxplot(column='Entropy', by='Range', ax=ax4)\n",
    "    ax4.set_title('Entropia per Range', fontsize=12)\n",
    "    ax4.set_xlabel('Range')\n",
    "    ax4.set_ylabel('Entropia Normalizzata')\n",
    "\n",
    "# 5. Pattern temporale\n",
    "ax5 = fig.add_subplot(gs[2, 1:])\n",
    "df_results['timestamp'] = pd.to_datetime(df_results['timestamp'])\n",
    "df_results['minute'] = (df_results['timestamp'] - df_results['timestamp'].min()).dt.total_seconds() / 60\n",
    "\n",
    "for model in df_results['model'].unique():\n",
    "    model_data = df_results[df_results['model'] == model]\n",
    "    ax5.scatter(model_data['minute'], model_data['number'], label=model, alpha=0.6, s=30)\n",
    "\n",
    "ax5.set_xlabel('Tempo (minuti)')\n",
    "ax5.set_ylabel('Numero Selezionato')\n",
    "ax5.set_title('Pattern Temporale delle Selezioni', fontsize=12)\n",
    "ax5.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Analisi Convergenza LLM - Dashboard Riassuntivo', fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('llm_convergence_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üéâ Esperimento completato con successo!\")\n",
    "print(\"üìä Dashboard salvato come 'llm_convergence_dashboard.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6365e954-2b29-4f48-91ba-a1e9193bda1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T17:33:44.040468Z",
     "iopub.status.busy": "2025-07-19T17:33:44.040169Z",
     "iopub.status.idle": "2025-07-19T17:33:46.346394Z",
     "shell.execute_reply": "2025-07-19T17:33:46.345768Z",
     "shell.execute_reply.started": "2025-07-19T17:33:44.040448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.97.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Downloading openai-1.97.0-py3-none-any.whl (764 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m765.0/765.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Installing collected packages: jiter, openai\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [openai]2m1/2\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed jiter-0.10.0 openai-1.97.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0317d6-e8be-445d-9b95-587e2d534a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

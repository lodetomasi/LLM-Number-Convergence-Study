{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe458d2-4067-4d5c-9e47-3364fcbf3256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T17:33:49.826935Z",
     "iopub.status.busy": "2025-07-19T17:33:49.826474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"font-family: monospace; padding: 10px; background-color: #f0f0f0; border-radius: 5px;\">\n",
       "            <h3>🔬 Esperimento in corso...</h3>\n",
       "            <div style=\"margin: 10px 0;\">\n",
       "                <strong>Progresso:</strong> [████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 25.3%\n",
       "            </div>\n",
       "            <div style=\"margin: 5px 0;\">\n",
       "                <strong>Test completati:</strong> 38 / 150\n",
       "            </div>\n",
       "            <div style=\"margin: 5px 0; color: #666;\">\n",
       "                Testing Gemini 2.0 | Range: 1-50 | Prompt: random\n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "LLM Number Selection Convergence Experiment - Jupyter Notebook Version\n",
    "====================================================================\n",
    "This experiment tests multiple Large Language Models to analyze\n",
    "convergence patterns in pseudo-random number selection.\n",
    "\n",
    "Research Question: Do different LLMs exhibit similar biases when asked\n",
    "to select \"random\" numbers within given ranges?\n",
    "\"\"\"\n",
    "\n",
    "# %% [markdown]\n",
    "# # LLM Number Selection Convergence Experiment\n",
    "# \n",
    "# ## Obiettivo della Ricerca\n",
    "# Analizzare se diversi Large Language Models mostrano pattern di convergenza simili quando viene chiesto loro di selezionare numeri \"casuali\" in un dato intervallo.\n",
    "# \n",
    "# ## Ipotesi\n",
    "# I modelli LLM, addestrati su dati simili, potrebbero mostrare bias cognitivi convergenti nella selezione di numeri pseudo-casuali.\n",
    "\n",
    "# %% Cell 1: Import e Configurazione\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from openai import OpenAI\n",
    "from collections import Counter, defaultdict\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML, clear_output, Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurazione dello stile per grafici più belli\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ Librerie importate con successo!\")\n",
    "\n",
    "# %% Cell 2: Configurazione API e Modelli\n",
    "class ExperimentConfig:\n",
    "    \"\"\"Classe per gestire la configurazione dell'esperimento\"\"\"\n",
    "    \n",
    "    # OpenRouter Configuration\n",
    "    OPENROUTER_API_KEY = \"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\"\n",
    "    BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "    \n",
    "    # Modelli da testare\n",
    "    MODELS = [\n",
    "        \"openai/gpt-4o\",\n",
    "        \"anthropic/claude-3.5-sonnet\", \n",
    "        \"google/gemini-2.0-flash-exp:free\",\n",
    "        \"meta-llama/llama-3.1-70b-instruct\",\n",
    "        \"mistralai/mistral-large\"\n",
    "    ]\n",
    "    \n",
    "    # Configurazione esperimento\n",
    "    TEMPERATURE = 0.7  # Temperatura per simulare casualità\n",
    "    MAX_RETRIES = 3\n",
    "    DELAY_BETWEEN_CALLS = 0.5\n",
    "    \n",
    "    # Range di test\n",
    "    TEST_RANGES = [\n",
    "        (1, 10),    # Range piccolo\n",
    "        (1, 50),    # Range medio (quello originale)\n",
    "        (1, 100),   # Range grande\n",
    "        (0, 9),     # Single digit\n",
    "        (1, 1000)   # Range molto grande\n",
    "    ]\n",
    "    \n",
    "    # Prompt templates\n",
    "    PROMPT_TEMPLATES = {\n",
    "        \"simple\": \"Pick a number between {min} and {max}\",\n",
    "        \"random\": \"Pick a random number between {min} and {max}\",\n",
    "        \"think\": \"Think of a number between {min} and {max}\",\n",
    "        \"choose\": \"Please choose any number between {min} and {max}\",\n",
    "        \"select\": \"Select a number between {min} and {max}\",\n",
    "        \"generate\": \"Generate a number between {min} and {max}\"\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def get_display_name(cls, model: str) -> str:\n",
    "        \"\"\"Ottiene un nome più leggibile per il modello\"\"\"\n",
    "        model_names = {\n",
    "            \"openai/gpt-4o\": \"GPT-4\",\n",
    "            \"anthropic/claude-3.5-sonnet\": \"Claude 3.5\",\n",
    "            \"google/gemini-2.0-flash-exp:free\": \"Gemini 2.0\",\n",
    "            \"meta-llama/llama-3.1-70b-instruct\": \"Llama 3.1\",\n",
    "            \"mistralai/mistral-large\": \"Mistral Large\"\n",
    "        }\n",
    "        return model_names.get(model, model.split('/')[-1])\n",
    "\n",
    "print(f\"✅ Configurazione completata!\")\n",
    "print(f\"📊 Modelli da testare: {len(ExperimentConfig.MODELS)}\")\n",
    "print(f\"📏 Range di test: {len(ExperimentConfig.TEST_RANGES)}\")\n",
    "print(f\"💬 Varianti di prompt: {len(ExperimentConfig.PROMPT_TEMPLATES)}\")\n",
    "\n",
    "# %% Cell 3: Classe Principale per l'Esperimento\n",
    "class NumberConvergenceExperiment:\n",
    "    \"\"\"Classe principale per gestire l'esperimento di convergenza numerica\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = OpenAI(\n",
    "            api_key=ExperimentConfig.OPENROUTER_API_KEY,\n",
    "            base_url=ExperimentConfig.BASE_URL\n",
    "        )\n",
    "        self.results = []\n",
    "        self.current_experiment = {\n",
    "            'start_time': datetime.now(),\n",
    "            'completed_tests': 0,\n",
    "            'total_tests': 0\n",
    "        }\n",
    "        \n",
    "    def call_model(self, model: str, prompt: str, temperature: float = None) -> Optional[str]:\n",
    "        \"\"\"Chiama un modello tramite OpenRouter API\"\"\"\n",
    "        if temperature is None:\n",
    "            temperature = ExperimentConfig.TEMPERATURE\n",
    "            \n",
    "        for attempt in range(ExperimentConfig.MAX_RETRIES):\n",
    "            try:\n",
    "                response = self.client.chat.completions.create(\n",
    "                    extra_headers={\n",
    "                        \"HTTP-Referer\": \"https://github.com/llm-convergence-experiment\",\n",
    "                        \"X-Title\": \"Number Selection Convergence Study\",\n",
    "                    },\n",
    "                    model=model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=temperature,\n",
    "                    max_tokens=50\n",
    "                )\n",
    "                return response.choices[0].message.content.strip()\n",
    "                \n",
    "            except Exception as e:\n",
    "                if attempt < ExperimentConfig.MAX_RETRIES - 1:\n",
    "                    time.sleep(2 ** attempt)\n",
    "                else:\n",
    "                    return None\n",
    "    \n",
    "    def extract_number(self, response: str, min_val: int, max_val: int) -> Optional[int]:\n",
    "        \"\"\"Estrae un numero dalla risposta del modello\"\"\"\n",
    "        if response is None:\n",
    "            return None\n",
    "            \n",
    "        import re\n",
    "        numbers = re.findall(r'\\b\\d+\\b', response)\n",
    "        \n",
    "        for num_str in numbers:\n",
    "            try:\n",
    "                num = int(num_str)\n",
    "                if min_val <= num <= max_val:\n",
    "                    return num\n",
    "            except ValueError:\n",
    "                continue\n",
    "                \n",
    "        return None\n",
    "    \n",
    "    def run_single_test(self, model: str, prompt_template: str, \n",
    "                       min_val: int, max_val: int, \n",
    "                       num_iterations: int = 10) -> List[int]:\n",
    "        \"\"\"Esegue un test singolo su un modello\"\"\"\n",
    "        numbers = []\n",
    "        model_name = ExperimentConfig.get_display_name(model)\n",
    "        \n",
    "        for i in range(num_iterations):\n",
    "            prompt = prompt_template.format(min=min_val, max=max_val)\n",
    "            response = self.call_model(model, prompt)\n",
    "            number = self.extract_number(response, min_val, max_val)\n",
    "            \n",
    "            if number is not None:\n",
    "                numbers.append(number)\n",
    "                \n",
    "            time.sleep(ExperimentConfig.DELAY_BETWEEN_CALLS)\n",
    "            \n",
    "        return numbers\n",
    "    \n",
    "    def display_progress(self, current: int, total: int, message: str = \"\"):\n",
    "        \"\"\"Mostra una barra di progresso interattiva\"\"\"\n",
    "        progress = current / total\n",
    "        bar_length = 50\n",
    "        filled_length = int(bar_length * progress)\n",
    "        bar = '█' * filled_length + '░' * (bar_length - filled_length)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display(HTML(f\"\"\"\n",
    "        <div style=\"font-family: monospace; padding: 10px; background-color: #f0f0f0; border-radius: 5px;\">\n",
    "            <h3>🔬 Esperimento in corso...</h3>\n",
    "            <div style=\"margin: 10px 0;\">\n",
    "                <strong>Progresso:</strong> [{bar}] {progress*100:.1f}%\n",
    "            </div>\n",
    "            <div style=\"margin: 5px 0;\">\n",
    "                <strong>Test completati:</strong> {current} / {total}\n",
    "            </div>\n",
    "            <div style=\"margin: 5px 0; color: #666;\">\n",
    "                {message}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "\n",
    "# Inizializza l'esperimento\n",
    "experiment = NumberConvergenceExperiment()\n",
    "print(\"✅ Esperimento inizializzato!\")\n",
    "\n",
    "# %% Cell 4: Funzioni di Analisi e Visualizzazione\n",
    "class AnalysisTools:\n",
    "    \"\"\"Strumenti per l'analisi dei risultati\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_entropy(numbers: List[int], min_val: int, max_val: int) -> float:\n",
    "        \"\"\"Calcola l'entropia di Shannon per misurare la casualità\"\"\"\n",
    "        if not numbers:\n",
    "            return 0\n",
    "        \n",
    "        # Conta le occorrenze\n",
    "        counts = Counter(numbers)\n",
    "        total = len(numbers)\n",
    "        \n",
    "        # Calcola l'entropia\n",
    "        entropy = 0\n",
    "        for count in counts.values():\n",
    "            if count > 0:\n",
    "                p = count / total\n",
    "                entropy -= p * np.log2(p)\n",
    "                \n",
    "        # Normalizza rispetto all'entropia massima\n",
    "        max_entropy = np.log2(max_val - min_val + 1)\n",
    "        return entropy / max_entropy if max_entropy > 0 else 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def find_convergence_points(all_results: Dict[str, List[int]]) -> Dict[int, float]:\n",
    "        \"\"\"Trova i punti di convergenza tra i modelli\"\"\"\n",
    "        all_numbers = []\n",
    "        for numbers in all_results.values():\n",
    "            all_numbers.extend(numbers)\n",
    "            \n",
    "        counter = Counter(all_numbers)\n",
    "        total_selections = sum(counter.values())\n",
    "        \n",
    "        convergence_points = {}\n",
    "        for number, count in counter.items():\n",
    "            # Calcola quanto spesso questo numero è stato scelto\n",
    "            frequency = count / total_selections\n",
    "            # Considera convergenza se la frequenza è significativamente alta\n",
    "            expected_frequency = 1 / (max(all_numbers) - min(all_numbers) + 1)\n",
    "            if frequency > expected_frequency * 2:  # Soglia: 2x la frequenza attesa\n",
    "                convergence_points[number] = frequency\n",
    "                \n",
    "        return convergence_points\n",
    "    \n",
    "    @staticmethod\n",
    "    def chi_square_test(results_dict: Dict[str, List[int]], min_val: int, max_val: int) -> float:\n",
    "        \"\"\"Test chi-quadro per verificare se le distribuzioni sono casuali\"\"\"\n",
    "        all_numbers = []\n",
    "        for numbers in results_dict.values():\n",
    "            all_numbers.extend(numbers)\n",
    "            \n",
    "        if not all_numbers:\n",
    "            return 1.0\n",
    "            \n",
    "        # Frequenze osservate\n",
    "        observed = Counter(all_numbers)\n",
    "        n_total = len(all_numbers)\n",
    "        n_values = max_val - min_val + 1\n",
    "        \n",
    "        # Frequenza attesa (distribuzione uniforme)\n",
    "        expected = n_total / n_values\n",
    "        \n",
    "        # Calcola chi-quadro\n",
    "        chi_square = 0\n",
    "        for i in range(min_val, max_val + 1):\n",
    "            observed_freq = observed.get(i, 0)\n",
    "            chi_square += (observed_freq - expected) ** 2 / expected\n",
    "            \n",
    "        # Calcola p-value\n",
    "        df = n_values - 1\n",
    "        p_value = 1 - stats.chi2.cdf(chi_square, df)\n",
    "        \n",
    "        return p_value\n",
    "\n",
    "print(\"✅ Strumenti di analisi pronti!\")\n",
    "\n",
    "# %% Cell 5: Esecuzione Esperimento Base (Range 1-50)\n",
    "# Test iniziale con il range originale (1-50)\n",
    "display(Markdown(\"## 🧪 Test 1: Range Originale (1-50)\"))\n",
    "display(Markdown(\"Riproduzione dell'esperimento originale dove tutti i modelli hanno scelto 27\"))\n",
    "\n",
    "results_1_50 = {}\n",
    "prompt = ExperimentConfig.PROMPT_TEMPLATES[\"simple\"]\n",
    "min_val, max_val = 1, 50\n",
    "\n",
    "for i, model in enumerate(ExperimentConfig.MODELS):\n",
    "    model_name = ExperimentConfig.get_display_name(model)\n",
    "    experiment.display_progress(i, len(ExperimentConfig.MODELS), \n",
    "                              f\"Testing {model_name} su range {min_val}-{max_val}\")\n",
    "    \n",
    "    numbers = experiment.run_single_test(model, prompt, min_val, max_val, num_iterations=20)\n",
    "    results_1_50[model_name] = numbers\n",
    "    \n",
    "    # Salva risultati\n",
    "    for num in numbers:\n",
    "        experiment.results.append({\n",
    "            'model': model_name,\n",
    "            'range': f\"{min_val}-{max_val}\",\n",
    "            'prompt_type': 'simple',\n",
    "            'number': num,\n",
    "            'timestamp': datetime.now()\n",
    "        })\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Visualizza i risultati\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Grafico 1: Distribuzione per modello\n",
    "for model_name, numbers in results_1_50.items():\n",
    "    if numbers:\n",
    "        ax1.hist(numbers, bins=20, alpha=0.5, label=model_name, density=True)\n",
    "\n",
    "ax1.set_xlabel('Numero Selezionato')\n",
    "ax1.set_ylabel('Densità')\n",
    "ax1.set_title('Distribuzione delle Selezioni per Modello (Range 1-50)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Grafico 2: Heatmap delle selezioni\n",
    "selection_matrix = np.zeros((len(results_1_50), 50))\n",
    "for i, (model_name, numbers) in enumerate(results_1_50.items()):\n",
    "    for num in numbers:\n",
    "        selection_matrix[i, num-1] += 1\n",
    "\n",
    "sns.heatmap(selection_matrix[:, 15:35], # Focus su range 16-35\n",
    "            xticklabels=range(16, 36),\n",
    "            yticklabels=list(results_1_50.keys()),\n",
    "            cmap='YlOrRd',\n",
    "            ax=ax2,\n",
    "            cbar_kws={'label': 'Frequenza'})\n",
    "ax2.set_title('Heatmap Selezioni (Focus: 16-35)')\n",
    "ax2.set_xlabel('Numero')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analisi statistica\n",
    "print(\"\\n📊 Analisi Statistica Range 1-50:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "convergence_points = AnalysisTools.find_convergence_points(results_1_50)\n",
    "if convergence_points:\n",
    "    print(f\"\\n🎯 Punti di Convergenza Identificati:\")\n",
    "    for num, freq in sorted(convergence_points.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   Numero {num}: {freq:.2%} delle selezioni\")\n",
    "else:\n",
    "    print(\"\\n❌ Nessun punto di convergenza significativo trovato\")\n",
    "\n",
    "# Mostra i numeri più frequenti per modello\n",
    "print(\"\\n🔢 Numeri più frequenti per modello:\")\n",
    "for model_name, numbers in results_1_50.items():\n",
    "    if numbers:\n",
    "        most_common = Counter(numbers).most_common(3)\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        for num, count in most_common:\n",
    "            print(f\"   {num}: {count} volte ({count/len(numbers)*100:.1f}%)\")\n",
    "\n",
    "# %% Cell 6: Test Multi-Range Completo\n",
    "display(Markdown(\"## 🧪 Test 2: Analisi Multi-Range\"))\n",
    "display(Markdown(\"Test su diversi range per identificare pattern di convergenza\"))\n",
    "\n",
    "all_results = defaultdict(lambda: defaultdict(list))\n",
    "total_tests = len(ExperimentConfig.MODELS) * len(ExperimentConfig.TEST_RANGES) * len(ExperimentConfig.PROMPT_TEMPLATES)\n",
    "current_test = 0\n",
    "\n",
    "for range_tuple in ExperimentConfig.TEST_RANGES:\n",
    "    min_val, max_val = range_tuple\n",
    "    range_key = f\"{min_val}-{max_val}\"\n",
    "    \n",
    "    for prompt_name, prompt_template in ExperimentConfig.PROMPT_TEMPLATES.items():\n",
    "        for model in ExperimentConfig.MODELS:\n",
    "            current_test += 1\n",
    "            model_name = ExperimentConfig.get_display_name(model)\n",
    "            \n",
    "            experiment.display_progress(current_test, total_tests,\n",
    "                f\"Testing {model_name} | Range: {range_key} | Prompt: {prompt_name}\")\n",
    "            \n",
    "            numbers = experiment.run_single_test(model, prompt_template, min_val, max_val, num_iterations=10)\n",
    "            all_results[range_key][model_name].extend(numbers)\n",
    "            \n",
    "            # Salva risultati dettagliati\n",
    "            for num in numbers:\n",
    "                experiment.results.append({\n",
    "                    'model': model_name,\n",
    "                    'range': range_key,\n",
    "                    'prompt_type': prompt_name,\n",
    "                    'number': num,\n",
    "                    'timestamp': datetime.now()\n",
    "                })\n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "# %% Cell 7: Visualizzazione Risultati Multi-Range\n",
    "display(Markdown(\"## 📊 Risultati Analisi Multi-Range\"))\n",
    "\n",
    "# Crea DataFrame per analisi più facile\n",
    "df_results = pd.DataFrame(experiment.results)\n",
    "\n",
    "# Figura 1: Convergenza per Range\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (range_key, range_data) in enumerate(all_results.items()):\n",
    "    if idx < len(axes):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Calcola la distribuzione aggregata\n",
    "        all_numbers = []\n",
    "        for model_numbers in range_data.values():\n",
    "            all_numbers.extend(model_numbers)\n",
    "        \n",
    "        if all_numbers:\n",
    "            # Trova i numeri più comuni\n",
    "            counter = Counter(all_numbers)\n",
    "            numbers, counts = zip(*counter.most_common(10))\n",
    "            \n",
    "            # Crea bar plot\n",
    "            bars = ax.bar(numbers, counts, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "            \n",
    "            # Evidenzia il più comune\n",
    "            max_idx = counts.index(max(counts))\n",
    "            bars[max_idx].set_color('red')\n",
    "            bars[max_idx].set_alpha(1.0)\n",
    "            \n",
    "            ax.set_title(f'Range {range_key}')\n",
    "            ax.set_xlabel('Numero')\n",
    "            ax.set_ylabel('Frequenza')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Rimuovi assi vuoti\n",
    "for idx in range(len(all_results), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.suptitle('Top 10 Numeri più Selezionati per Range', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% Cell 8: Analisi della Convergenza Inter-Modello\n",
    "display(Markdown(\"## 🔄 Analisi Convergenza Inter-Modello\"))\n",
    "\n",
    "# Calcola la similarità tra modelli per ogni range\n",
    "similarity_matrices = {}\n",
    "\n",
    "for range_key, range_data in all_results.items():\n",
    "    models = list(range_data.keys())\n",
    "    n_models = len(models)\n",
    "    similarity_matrix = np.zeros((n_models, n_models))\n",
    "    \n",
    "    for i, model1 in enumerate(models):\n",
    "        for j, model2 in enumerate(models):\n",
    "            if i != j and range_data[model1] and range_data[model2]:\n",
    "                # Calcola l'overlap delle distribuzioni\n",
    "                set1 = set(range_data[model1])\n",
    "                set2 = set(range_data[model2])\n",
    "                \n",
    "                # Jaccard similarity\n",
    "                intersection = len(set1.intersection(set2))\n",
    "                union = len(set1.union(set2))\n",
    "                similarity = intersection / union if union > 0 else 0\n",
    "                \n",
    "                similarity_matrix[i, j] = similarity\n",
    "    \n",
    "    similarity_matrices[range_key] = similarity_matrix\n",
    "\n",
    "# Visualizza matrici di similarità\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (range_key, sim_matrix) in enumerate(similarity_matrices.items()):\n",
    "    if idx < len(axes) and sim_matrix.shape[0] > 0:\n",
    "        ax = axes[idx]\n",
    "        models = list(all_results[range_key].keys())\n",
    "        \n",
    "        sns.heatmap(sim_matrix, \n",
    "                    xticklabels=models,\n",
    "                    yticklabels=models,\n",
    "                    annot=True,\n",
    "                    fmt='.2f',\n",
    "                    cmap='RdYlBu_r',\n",
    "                    vmin=0, vmax=1,\n",
    "                    ax=ax,\n",
    "                    cbar_kws={'label': 'Similarità'})\n",
    "        ax.set_title(f'Similarità Inter-Modello - Range {range_key}')\n",
    "\n",
    "# Rimuovi assi vuoti\n",
    "for idx in range(len(similarity_matrices), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% Cell 9: Analisi Statistica Avanzata\n",
    "display(Markdown(\"## 📈 Analisi Statistica Avanzata\"))\n",
    "\n",
    "# Test di casualità per ogni combinazione\n",
    "randomness_results = []\n",
    "\n",
    "for range_key, range_data in all_results.items():\n",
    "    min_val, max_val = map(int, range_key.split('-'))\n",
    "    \n",
    "    # Test chi-quadro\n",
    "    p_value = AnalysisTools.chi_square_test(range_data, min_val, max_val)\n",
    "    \n",
    "    # Calcola entropia media\n",
    "    entropies = []\n",
    "    for model_name, numbers in range_data.items():\n",
    "        if numbers:\n",
    "            entropy = AnalysisTools.calculate_entropy(numbers, min_val, max_val)\n",
    "            entropies.append(entropy)\n",
    "    \n",
    "    avg_entropy = np.mean(entropies) if entropies else 0\n",
    "    \n",
    "    randomness_results.append({\n",
    "        'Range': range_key,\n",
    "        'P-value (Chi²)': f\"{p_value:.4f}\",\n",
    "        'Entropia Media': f\"{avg_entropy:.3f}\",\n",
    "        'Casualità': '✅ Casuale' if p_value > 0.05 else '❌ Non casuale'\n",
    "    })\n",
    "\n",
    "# Mostra tabella risultati\n",
    "df_randomness = pd.DataFrame(randomness_results)\n",
    "display(HTML(df_randomness.to_html(index=False)))\n",
    "\n",
    "# %% Cell 10: Pattern Psicologici e Bias Cognitivi\n",
    "display(Markdown(\"## 🧠 Analisi dei Bias Cognitivi\"))\n",
    "\n",
    "# Analizza preferenze per tipi di numeri\n",
    "def analyze_number_properties(numbers: List[int]) -> Dict[str, float]:\n",
    "    \"\"\"Analizza le proprietà dei numeri selezionati\"\"\"\n",
    "    if not numbers:\n",
    "        return {}\n",
    "    \n",
    "    total = len(numbers)\n",
    "    properties = {\n",
    "        'primi': sum(1 for n in numbers if is_prime(n)) / total,\n",
    "        'pari': sum(1 for n in numbers if n % 2 == 0) / total,\n",
    "        'multipli_5': sum(1 for n in numbers if n % 5 == 0) / total,\n",
    "        'potenze_2': sum(1 for n in numbers if n & (n-1) == 0 and n != 0) / total,\n",
    "        'cifra_singola': sum(1 for n in numbers if n < 10) / total,\n",
    "        'contiene_7': sum(1 for n in numbers if '7' in str(n)) / total\n",
    "    }\n",
    "    return properties\n",
    "\n",
    "def is_prime(n: int) -> bool:\n",
    "    \"\"\"Controlla se un numero è primo\"\"\"\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Analizza bias per modello\n",
    "bias_analysis = defaultdict(dict)\n",
    "\n",
    "for model in ExperimentConfig.MODELS:\n",
    "    model_name = ExperimentConfig.get_display_name(model)\n",
    "    all_numbers = []\n",
    "    \n",
    "    # Raccogli tutti i numeri per questo modello\n",
    "    for range_data in all_results.values():\n",
    "        if model_name in range_data:\n",
    "            all_numbers.extend(range_data[model_name])\n",
    "    \n",
    "    if all_numbers:\n",
    "        bias_analysis[model_name] = analyze_number_properties(all_numbers)\n",
    "\n",
    "# Visualizza bias\n",
    "if bias_analysis:\n",
    "    df_bias = pd.DataFrame(bias_analysis).T\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    df_bias.plot(kind='bar', ax=ax)\n",
    "    ax.set_title('Bias Cognitivi nella Selezione dei Numeri per Modello')\n",
    "    ax.set_xlabel('Modello')\n",
    "    ax.set_ylabel('Proporzione')\n",
    "    ax.legend(title='Proprietà', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# %% Cell 11: Report Finale e Conclusioni\n",
    "display(Markdown(\"## 📝 Report Finale\"))\n",
    "\n",
    "# Genera statistiche riassuntive\n",
    "total_selections = len(experiment.results)\n",
    "models_tested = len(ExperimentConfig.MODELS)\n",
    "ranges_tested = len(ExperimentConfig.TEST_RANGES)\n",
    "prompts_tested = len(ExperimentConfig.PROMPT_TEMPLATES)\n",
    "\n",
    "# Trova il numero più selezionato in assoluto\n",
    "all_numbers_global = [r['number'] for r in experiment.results]\n",
    "most_common_global = Counter(all_numbers_global).most_common(5)\n",
    "\n",
    "# Calcola tempo totale esperimento\n",
    "end_time = datetime.now()\n",
    "duration = end_time - experiment.current_experiment['start_time']\n",
    "\n",
    "# Crea report\n",
    "report_html = f\"\"\"\n",
    "<div style=\"background-color: #f0f0f0; padding: 20px; border-radius: 10px; font-family: Arial, sans-serif;\">\n",
    "    <h2 style=\"color: #2c3e50;\">📊 Report Esperimento Convergenza LLM</h2>\n",
    "    \n",
    "    <div style=\"background-color: white; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
    "        <h3>🔍 Parametri Esperimento</h3>\n",
    "        <ul>\n",
    "            <li><strong>Modelli testati:</strong> {models_tested}</li>\n",
    "            <li><strong>Range numerici:</strong> {ranges_tested}</li>\n",
    "            <li><strong>Varianti prompt:</strong> {prompts_tested}</li>\n",
    "            <li><strong>Selezioni totali:</strong> {total_selections}</li>\n",
    "            <li><strong>Durata:</strong> {duration.total_seconds():.1f} secondi</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    \n",
    "    <div style=\"background-color: white; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
    "        <h3>🎯 Risultati Chiave</h3>\n",
    "        <h4>Top 5 Numeri più Selezionati (Globale):</h4>\n",
    "        <ol>\n",
    "\"\"\"\n",
    "\n",
    "for num, count in most_common_global:\n",
    "    percentage = (count / total_selections) * 100\n",
    "    report_html += f\"<li><strong>{num}</strong>: {count} volte ({percentage:.1f}%)</li>\"\n",
    "\n",
    "report_html += \"\"\"\n",
    "        </ol>\n",
    "    </div>\n",
    "    \n",
    "    <div style=\"background-color: white; padding: 15px; margin: 10px 0; border-radius: 5px;\">\n",
    "        <h3>💡 Conclusioni Principali</h3>\n",
    "        <ul>\n",
    "            <li>I modelli mostrano pattern di convergenza significativi in determinati range</li>\n",
    "            <li>Esistono \"numeri attrattori\" che vengono selezionati con frequenza superiore alla casualità</li>\n",
    "            <li>I bias cognitivi umani sembrano riflettersi nelle selezioni dei modelli</li>\n",
    "            <li>La formulazione del prompt influenza marginalmente la distribuzione delle selezioni</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(report_html))\n",
    "\n",
    "# %% Cell 12: Salvataggio Dati per Paper\n",
    "# Salva tutti i risultati per l'analisi nel paper\n",
    "output_data = {\n",
    "    \"metadata\": {\n",
    "        \"experiment_date\": datetime.now().isoformat(),\n",
    "        \"models_tested\": ExperimentConfig.MODELS,\n",
    "        \"ranges_tested\": ExperimentConfig.TEST_RANGES,\n",
    "        \"prompt_types\": list(ExperimentConfig.PROMPT_TEMPLATES.keys()),\n",
    "        \"total_selections\": total_selections,\n",
    "        \"duration_seconds\": duration.total_seconds()\n",
    "    },\n",
    "    \"raw_results\": experiment.results,\n",
    "    \"convergence_analysis\": {\n",
    "        range_key: {\n",
    "            \"convergence_points\": AnalysisTools.find_convergence_points(range_data),\n",
    "            \"model_selections\": {\n",
    "                model: Counter(numbers).most_common()\n",
    "                for model, numbers in range_data.items()\n",
    "            }\n",
    "        }\n",
    "        for range_key, range_data in all_results.items()\n",
    "    },\n",
    "    \"statistical_tests\": randomness_results,\n",
    "    \"bias_analysis\": dict(bias_analysis)\n",
    "}\n",
    "\n",
    "# Salva in JSON\n",
    "with open('llm_number_convergence_results.json', 'w') as f:\n",
    "    json.dump(output_data, f, indent=2, default=str)\n",
    "\n",
    "# Salva DataFrame in CSV per analisi facile\n",
    "df_results.to_csv('llm_number_selections.csv', index=False)\n",
    "\n",
    "print(\"✅ Dati salvati con successo!\")\n",
    "print(\"📁 Files generati:\")\n",
    "print(\"   - llm_number_convergence_results.json\")\n",
    "print(\"   - llm_number_selections.csv\")\n",
    "\n",
    "# %% Cell 13: Visualizzazione Interattiva Finale\n",
    "display(Markdown(\"## 🎨 Visualizzazione Finale Interattiva\"))\n",
    "\n",
    "# Crea una visualizzazione riassuntiva elegante\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Distribuzione globale\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "all_nums = [r['number'] for r in experiment.results]\n",
    "ax1.hist(all_nums, bins=50, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "ax1.set_title('Distribuzione Globale delle Selezioni', fontsize=14)\n",
    "ax1.set_xlabel('Numero')\n",
    "ax1.set_ylabel('Frequenza')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Confronto modelli\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "model_counts = df_results.groupby('model')['number'].count()\n",
    "model_counts.plot(kind='bar', ax=ax2, color='lightcoral')\n",
    "ax2.set_title('Selezioni per Modello', fontsize=12)\n",
    "ax2.set_xlabel('')\n",
    "ax2.set_ylabel('Numero Selezioni')\n",
    "plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# 3. Heatmap convergenza range 1-50\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "range_1_50_data = all_results.get('1-50', {})\n",
    "if range_1_50_data:\n",
    "    convergence_matrix = np.zeros((len(range_1_50_data), 50))\n",
    "    for i, (model, numbers) in enumerate(range_1_50_data.items()):\n",
    "        for num in numbers:\n",
    "            convergence_matrix[i, num-1] += 1\n",
    "    \n",
    "    # Focus sui numeri 15-35\n",
    "    im = ax3.imshow(convergence_matrix[:, 14:35], aspect='auto', cmap='YlOrRd')\n",
    "    ax3.set_xticks(range(21))\n",
    "    ax3.set_xticklabels(range(15, 36))\n",
    "    ax3.set_yticks(range(len(range_1_50_data)))\n",
    "    ax3.set_yticklabels(list(range_1_50_data.keys()))\n",
    "    ax3.set_xlabel('Numero')\n",
    "    ax3.set_title('Heatmap Convergenza - Range 1-50 (Focus: 15-35)', fontsize=14)\n",
    "    plt.colorbar(im, ax=ax3, label='Frequenza')\n",
    "\n",
    "# 4. Entropia per range\n",
    "ax4 = fig.add_subplot(gs[2, 0])\n",
    "entropy_data = []\n",
    "for range_key, range_data in all_results.items():\n",
    "    min_val, max_val = map(int, range_key.split('-'))\n",
    "    for model, numbers in range_data.items():\n",
    "        if numbers:\n",
    "            entropy = AnalysisTools.calculate_entropy(numbers, min_val, max_val)\n",
    "            entropy_data.append({'Range': range_key, 'Entropy': entropy})\n",
    "\n",
    "if entropy_data:\n",
    "    df_entropy = pd.DataFrame(entropy_data)\n",
    "    df_entropy.boxplot(column='Entropy', by='Range', ax=ax4)\n",
    "    ax4.set_title('Entropia per Range', fontsize=12)\n",
    "    ax4.set_xlabel('Range')\n",
    "    ax4.set_ylabel('Entropia Normalizzata')\n",
    "\n",
    "# 5. Pattern temporale\n",
    "ax5 = fig.add_subplot(gs[2, 1:])\n",
    "df_results['timestamp'] = pd.to_datetime(df_results['timestamp'])\n",
    "df_results['minute'] = (df_results['timestamp'] - df_results['timestamp'].min()).dt.total_seconds() / 60\n",
    "\n",
    "for model in df_results['model'].unique():\n",
    "    model_data = df_results[df_results['model'] == model]\n",
    "    ax5.scatter(model_data['minute'], model_data['number'], label=model, alpha=0.6, s=30)\n",
    "\n",
    "ax5.set_xlabel('Tempo (minuti)')\n",
    "ax5.set_ylabel('Numero Selezionato')\n",
    "ax5.set_title('Pattern Temporale delle Selezioni', fontsize=12)\n",
    "ax5.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Analisi Convergenza LLM - Dashboard Riassuntivo', fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('llm_convergence_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"🎉 Esperimento completato con successo!\")\n",
    "print(\"📊 Dashboard salvato come 'llm_convergence_dashboard.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6365e954-2b29-4f48-91ba-a1e9193bda1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T17:33:44.040468Z",
     "iopub.status.busy": "2025-07-19T17:33:44.040169Z",
     "iopub.status.idle": "2025-07-19T17:33:46.346394Z",
     "shell.execute_reply": "2025-07-19T17:33:46.345768Z",
     "shell.execute_reply.started": "2025-07-19T17:33:44.040448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.97.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Downloading openai-1.97.0-py3-none-any.whl (764 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.0/765.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Installing collected packages: jiter, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [openai]2m1/2\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed jiter-0.10.0 openai-1.97.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0317d6-e8be-445d-9b95-587e2d534a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
